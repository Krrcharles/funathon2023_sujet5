{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... categorie : healthy\n",
      "chargement categorie:healthy fait\n",
      "loading... categorie : rot\n",
      "chargement categorie:rot fait\n",
      "loading... categorie : rust\n",
      "chargement categorie:rust fait\n",
      "Execution :  77.03166007995605  s\n"
     ]
    }
   ],
   "source": [
    "#Formatage des données\n",
    "#Cette partie nécéssite beacoup de RAM\n",
    "\n",
    "t1 = time.time()\n",
    "    \n",
    "Categories=['healthy','rot','rust'] #les différentes catégories qu'on traite\n",
    "\n",
    "flat_data_arr = [] #contient les images aplaties\n",
    "target_arr = [] #contient la sortie\n",
    "\n",
    "datadir='New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\\\\Apples'\n",
    "\n",
    "N_img_each = 1250 #nombre d'images par catégorie\n",
    "\n",
    "for i in Categories:\n",
    "    \n",
    "    print(f'loading... categorie : {i}')    \n",
    "    path=os.path.join(datadir,i)    \n",
    "    \n",
    "    for img in os.listdir(path)[:N_img_each]:#on prend N_img_each images par categories\n",
    "        \n",
    "        if not img.endswith('.JPG'):\n",
    "            continue\n",
    "        img_array=imread(os.path.join(path,img)) \n",
    "        img_resized=resize(img_array,(256,256,3))     #  \n",
    "        flat_data_arr.append(img_resized.flatten())   # On formate l'image pour numpy    \n",
    "        target_arr.append(Categories.index(i))        #\n",
    "    \n",
    "    print(f'chargement categorie:{i} fait')\n",
    "    \n",
    "flat_data=np.array(flat_data_arr) #\n",
    "target=np.array(target_arr)       #\n",
    "df=pd.DataFrame(flat_data)        # On formate l'image pour pandas\n",
    "df['Target']=target               #\n",
    "\n",
    "\n",
    "x=df.iloc[:,:-1] #entrée\n",
    "y=df.iloc[:,-1] #sortie \n",
    "\n",
    "print(\"Execution : \",  time.time()- t1, \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creation du modele avec recherche de kernel\n",
    "\n",
    "param_grid={'C':[10000],'gamma':[0.0001],'kernel':['rbf']}#Quelles valeures à tester                      \n",
    "svc=svm.SVC(probability=True)                                                   \n",
    "model=GridSearchCV(svc,param_grid)                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation du modele avec kernel defini\n",
    "\n",
    "kernel = 'rbf'\n",
    "gamma = 1e-4\n",
    "C = 1e5\n",
    "\n",
    "model = svm.SVC(C = C, kernel = kernel, gamma = gamma, probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation reussie\n"
     ]
    }
   ],
   "source": [
    "#On sépare les données en deux groupes: entrainement et test\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=77,stratify=y)\n",
    "\n",
    "print('Séparation reussie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution :  197.25702691078186  s\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "t1 = time.time()\n",
    "\n",
    "Ncomp = 2\n",
    "pca = PCA(Ncomp)\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "\n",
    "print(\"Execution : \", -t1 + time.time(), \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'entrainement\n",
      "Execution :  11.488438129425049  s\n"
     ]
    }
   ],
   "source": [
    "#Entrainement du model\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "model.fit(x_train,y_train) \n",
    "\n",
    "print(\"Fin de l'entrainement\")\n",
    "\n",
    "print(\"Execution : \", -t1 + time.time(), \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONEL\n",
    "#Stockage du model dans un fichier \n",
    "\n",
    "model_name = \" \"\n",
    "\n",
    "with open(model_name +\" \"+ str(N_img_each) + ' image', 'wb') as f1:\n",
    "    pickle.dump(model, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONEL\n",
    "#Importation d'un model\n",
    "\n",
    "file_name = \" \"\n",
    "\n",
    "with open('rbf auto 300', 'rb') as f1:\n",
    "    model = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision des prédiction :  0.9813333333333333\n",
      "\n",
      "\n",
      "Matrice de confusion : \n",
      "[[247   1   2]\n",
      " [  6 242   2]\n",
      " [  0   3 247]]\n"
     ]
    }
   ],
   "source": [
    "#Test du model\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "def accuracy(pred,real):\n",
    "    \"\"\"Calule la précision des prédictions pred par rapport à real \"\"\"\n",
    "    count = 0\n",
    "    L = len(pred)\n",
    "    for i in range(L):\n",
    "        if pred[i] == real[i]:\n",
    "            count += 1\n",
    "    return count/L\n",
    "\n",
    "\n",
    "def confusion_mat(pred,real):\n",
    "    \"\"\"Calcule la matrice de confusion des résultats\"\"\"\n",
    "    M = np.full((3,3), 0)\n",
    "    L = len(pred)\n",
    "    for i in range(L):\n",
    "        M[real[i]][pred[i]] += 1\n",
    "        \n",
    "    return M\n",
    "\n",
    "          \n",
    "print(\"Precision des prédiction : \", accuracy(y_pred,np.array(y_test)))\n",
    "print(\"\\n\\nMatrice de confusion : \")\n",
    "print(confusion_mat(y_pred,np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
